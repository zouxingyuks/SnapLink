# 部署文档

## 1. 准备原始配置文件

> 由于目前 docker compose 的长久功能缺失，导致我们还是需要手动复制配置文件

执行[`make_default_config.sh`](./make_default_config.sh) 获取默认配置文件

## 2. 启动 docker 环境并进行基本配置

```bash
docker compose up -d
```

### MySQL 配置

进入 `./docker_data/mysql` 文件夹

修改文件`my.cnf`

```
# 配置文件中添加如下内容，注意是在 [mysqld] 下方
[mysqld]
log-bin=mysql-bin  # 开启 binlog
binlog-format=ROW  # 选择 ROW 模式
server-id=1 # 配置 MySQL replaction 需要定义，不要和 maxwell 的 slaveId 重复
```

而后重启 MySQL 的容器。

使用命令`docker exec -it snaplink-mysql bash` 进入 docker 控制台

```mysql
mysql -u root -p
```

默认 root 密码为：`pjJdE#j:ovE-J:Vk1~?y`

使用`show variables like 'log%'; ` 查看配置

正确配置如下图所示：![](https://cimg.anubis.cafe/2024/04/2ffa1b8b9194a43e4b7049900ae0d1a2.webp)



接下来配置 maxwell 所需的账户

```sql
CREATE DATABASE maxwell;
-- 创建用户 maxwell
CREATE USER 'maxwell' IDENTIFIED BY 'maxwell';

GRANT SELECT, REPLICATION CLIENT, REPLICATION SLAVE on *.* to 'maxwell';
GRANT ALL ON maxwell.* TO 'maxwell'@'%';
FLUSH PRIVILEGES;

```

> 此处因需要考虑到创建时 ip 的变化，对账户并没有做 ip 限制





### RabbitMQ 配置

使用命令`docker exec -it snaplink-rabbitmq bash` 进入 docker 控制台

输入下列命令启用控制台：

```bash
rabbitmq-plugins enable rabbitmq_management
```

![](https://cimg.anubis.cafe/2024/04/1450c6ea4ef2e254b2b7cde6e16602c0.webp)

进入[控制台](http://localhost:15672/)，初始账户为

```
username: admin
password: password.123
```

创建 vHost,起名为 maxwell

![](https://cimg.anubis.cafe/2024/04/8bb29b59891fdb65263bb08036d14f69.webp)

创建用户

```
maxwell
maxwell
```

![](https://cimg.anubis.cafe/2024/04/2908bdf3cdbb7f72f6669a08e2ec948b.webp)

给用户赋予 maxwell 这个 vHost 的访问权限

![](https://cimg.anubis.cafe/2024/04/5fcb5c8ac02036b48c06859fe12eb86b.webp)

创建用户

> 此账户是给后面的 elk 套件使用的

```
elk
elk
```

同样，创建 accesslog 这个 vHost ，步骤同上，为 elk 赋予访问 accesslog 这个 vHost 的权限

### Maxwell 配置

> 此处配置需要在前两个配置完成后才可以配置

在 `./docker_data/maxwell` 文件夹中创建`config.properties`

```
# tl;dr 配置
log_level=DEBUG

producer=rabbitmq


# mysql 登录信息
host=snaplink-mysql
port=3306
user=maxwell
password=maxwell

# rabbitmq 配置信息
rabbitmq_host=snaplink-rabbitmq
rabbitmq_port=5672
#此处填写前面创建的 rabbitmq 用户
rabbitmq_user=maxwell
rabbitmq_pass=maxwell
rabbitmq_virtual_host=maxwell
rabbitmq_exchange=maxwell.topic
rabbitmq_exchange_type=topic
rabbitmq_routing_key_template=%db%.%table%

#     *** 通用配置 ***
# 选择数据输出目的地。支持 stdout|file|kafka|kinesis|pubsub|sqs|rabbitmq|redis|bigquery
#producer=kafka

# 设置日志级别。注意，你可以在 log4j2.xml 中进一步配置
#log_level=DEBUG # [DEBUG, INFO, WARN, ERROR]

# 如果设置，maxwell 会查找限定环境变量，去掉前缀并注入配置
#env_config_prefix=MAXWELL_

#     *** MySQL 配置 ***

# 要连接的 MySQL 主机
#host=hostname

# 要连接的 MySQL 端口
#port=3306

# MySQL 用户名。此用户必须拥有 REPLICATION SLAVE 权限，
# 以及对 `maxwell`（或 schema_database）数据库的完全访问权限
#user=maxwell

# MySQL 密码
#password=maxwell

# 传递给 jdbc 连接的选项，格式为 opt=val&opt2=val2
#jdbc_options=opt1=100&opt2=hello

# maxwell 保存其状态的 MySQL 数据库名称
#schema_database=maxwell

# 是否使用 GTID 进行定位
#gtid_mode=true

# maxwell 会捕获一个初始的“基础”架构，包含所有表和列信息，
# 然后在该架构上保持增量更新。如果你有过多的 DDL 变更，
# 包含增量变更的表会随时间无限制增长（可能变得过大）。如果启用此选项，
# Maxwell 会定期压缩其表。
#max_schemas=10000

# SSL/TLS 选项
# 使用 VERIFY_CA 或 VERIFY_IDENTITY 时，必须使用 Java opts 设置信任库：
#   -Djavax.net.ssl.trustStore=<truststore> -Djavax.net.ssl.trustStorePassword=<password>
# 或将 MySQL 证书导入全局 Java cacerts。
# MODE 必须是 DISABLED, PREFERRED, REQUIRED, VERIFY_CA, 或 VERIFY_IDENTITY 其中之一
#
# 开启 maxwell-store 连接的 ssl，其他连接继承此设置，除非另有指定
#ssl=DISABLED
# 对于 binlog-connector
#replication_ssl=DISABLED
# 对于 schema-capture 连接，如果使用
#schema_ssl=DISABLED

# maxwell 可以选择性地从不同于存储
# schema 和 binlog 位置信息的服务器复制。在这里指定那个不同的服务器：

#replication_host=other
#replication_user=username
#replication_password=password
#replication_port=3306

# 当使用 MaxScale 的 binlog 镜像主机时可能有用。
# 指定 Maxwell 应该从与它复制的不同服务器捕获 schema：

#schema_host=other
#schema_user=username
#schema_password=password
#schema_port=3306


#       *** 输出格式 ***

# 记录是否包括 binlog 位置（默认为 false）
#output_binlog_position=true

# 记录是否包含 gtid 字符串（默认为 false）
#output_gtid_position=true

# 记录是否包括具有 null 值的字段（默认为 true）。如果为 false，
# 值为 null 的字段将完全从输出中省略。
#output_nulls=true

# 记录是否包括 server_id（默认为 false）
#output_server_id=true

# 记录是否包括 thread_id（默认为 false）
#output_thread_id=true

# 记录是否包括 schema_id（默认为 false）
#output_schema_id=true

# 记录是否包括 row query，必须启用 binlog 选项 "binlog_rows_query_log_events"（默认为 false）
#output_row_query=true

# DML 记录是否包含组成行主键的值列表（默认为 false）
#output_primary_keys=true

# DML 记录是否包含组成行主键的列列表（默认为 false）
```

配置完成后再次启动 maxwell 这个容器

### ELK 配置

#### elasticsearch 配置

修改 `./docker_data/elk/elasticsearch.yml` 文件，使用下列信息进行覆盖

```yaml
## Default Elasticsearch configuration from Elasticsearch base image.
## https://github.com/elastic/elasticsearch/blob/main/distribution/docker/src/docker/config/elasticsearch.yml
#
cluster.name: docker-cluster
network.host: 0.0.0.0

## X-Pack settings
## see https://www.elastic.co/guide/en/elasticsearch/reference/current/security-settings.html
#
xpack.license.self_generated.type: trial
xpack.security.enabled: true

```

重新启动，使用`docker exec -it snaplink-elasticsearch bash`进入后执行下列命令

```bash
mkdir roles
cd ./roles
cat > logstash_writer.json <<'EOF'
{
  "cluster": [
    "manage_index_templates",
    "monitor",
    "manage_ilm"
  ],
  "indices": [
    {
      "names": [
        "logs-generic-default",
        "logstash-*",
        "ecs-logstash-*"
      ],
      "privileges": [
        "write",
        "create",
        "create_index",
        "manage",
        "manage_ilm"
      ]
    },
    {
      "names": [
        "logstash",
        "ecs-logstash"
      ],
      "privileges": [
        "write",
        "manage"
      ]
    }
  ]
}
EOF
cat > metricbeat_writer.json <<'EOF'
{
  "cluster": [
    "manage_ilm",
    "manage_index_templates",
    "monitor"
  ],
  "indices": [
    {
      "names": [
        ".monitoring-*-mb",
        "metricbeat-*"
      ],
      "privileges": [
        "create_doc",
        "manage"
      ]
    }
  ]
}
EOF
cat > heartbeat_writer.json <<'EOF'
{
  "cluster": [
    "manage_ilm",
    "manage_index_templates",
    "monitor"
  ],
  "indices": [
    {
      "names": [
        "heartbeat-*"
      ],
      "privileges": [
        "create_doc",
        "manage"
      ]
    }
  ]
}
EOF
cat > filebeat_writer.json <<'EOF'
{
  "cluster": [
    "manage_ilm",
    "manage_index_templates",
    "monitor",
    "read_pipeline"
  ],
  "indices": [
    {
      "names": [
        "filebeat-*"
      ],
      "privileges": [
        "create_doc",
        "manage"
      ]
    }
  ]
}
EOF
cd ..
cat > lib.sh <<'EOF'
#!/usr/bin/env bash

# Log a message.
function log {
	echo "[+] $1"
}

# Log a message at a sub-level.
function sublog {
	echo "   ⠿ $1"
}

# Log an error.
function err {
	echo "[x] $1" >&2
}

# Log an error at a sub-level.
function suberr {
	echo "   ⠍ $1" >&2
}

# Poll the 'elasticsearch' service until it responds with HTTP code 200.
function wait_for_elasticsearch {
    local -a args=( '-s' '-D-' '-m15' '-w' '%{http_code}' "http://localhost:9200/" )

    if [[ -n "${ELASTIC_PASSWORD:-}" ]]; then
        args+=( '-u' "elastic:${ELASTIC_PASSWORD}" )
    fi

    local -i result=1
    local output

    echo "Waiting for Elasticsearch at ${args[3]}"

    # retry for max 300s (60*5s)
    for attempt in $(seq 1 60); do
        echo "Attempt $attempt of 60"
        output="$(curl "${args[@]}")"
        local status_code="${output: -3}"
        echo "HTTP Status Code: $status_code"

        if [[ "$status_code" -eq 200 ]]; then
            echo "Elasticsearch is up and running."
            result=0
            break
        else
            echo "Elasticsearch is not ready yet."
        fi

        sleep 5
    done

    if [[ "$result" -ne 0 ]]; then
        echo "Failed to connect to Elasticsearch within the expected time frame."
        echo "Last HTTP Status Code: $status_code"
        echo "Last Response Body: ${output::-3}"
    fi

    return $result
}
# Poll the Elasticsearch users API until it returns users.
function wait_for_builtin_users {
    local -a args=( '-s' '-D-' '-m15' "http://localhost:9200/_security/user?pretty" )

    if [[ -n "${ELASTIC_PASSWORD:-}" ]]; then
        args+=( '-u' "elastic:${ELASTIC_PASSWORD}" )
    fi

    local -i result=1
    local -i exit_code=0
    local -i num_users=0

    # retry for max 30s (30*1s)
    for _ in $(seq 1 30); do
        exit_code=0
        # Execute curl and process its output in a while loop
        num_users=$(curl "${args[@]}" | while IFS= read -r line; do
            if [[ "$line" =~ _reserved.+true ]]; then
                (( num_users++ ))
            fi
            echo "$num_users"  # 输出当前的 num_users 值
        done | tail -n 1)  # 只获取最后一次输出的 num_users 值
        echo $num_users

        # Check the exit code of the curl command
        exit_code=$?

        if (( exit_code )); then
            suberr "Curl command failed with exit code: $exit_code"
            result=$exit_code
        fi

        # we expect more than just the 'elastic' user in the result
        if (( num_users > 1 )); then
            result=0
            break
        fi

        sublog "Attempt $(( num_users + 1 )): Users found: $num_users"

        sleep 1
    done

    if ((result)); then
        suberr "Timed out waiting for condition"
    else
        sublog "Built-in users were initialized"
    fi

    return $result
}



# Verify that the given Elasticsearch user exists.
function check_user_exists {
	local username=$1
	local -a args=( '-s' '-D-' '-m15' '-w' '%{http_code}'
		"http://localhost:9200/_security/user/${username}"
		)

	if [[ -n "${ELASTIC_PASSWORD:-}" ]]; then
		args+=( '-u' "elastic:${ELASTIC_PASSWORD}" )
	fi

	local -i result=1
	local -i exists=0
	local output

	output="$(curl "${args[@]}")"
	if [[ "${output: -3}" -eq 200 || "${output: -3}" -eq 404 ]]; then
		result=0
	fi
	if [[ "${output: -3}" -eq 200 ]]; then
		exists=1
	fi

	if ((result)); then
		echo -e "\n${output::-3}"
	else
		echo "$exists"
	fi

	return $result
}

# Set password of a given Elasticsearch user.
function set_user_password {
	local username=$1
	local password=$2
	local -a args=( '-s' '-D-' '-m15' '-w' '%{http_code}'
		"http://localhost:9200/_security/user/${username}/_password"
		'-X' 'POST'
		'-H' 'Content-Type: application/json'
		'-d' "{\"password\" : \"${password}\"}"
		)

	if [[ -n "${ELASTIC_PASSWORD:-}" ]]; then
		args+=( '-u' "elastic:${ELASTIC_PASSWORD}" )
	fi

	local -i result=1
	local output

	output="$(curl "${args[@]}")"
	if [[ "${output: -3}" -eq 200 ]]; then
		result=0
	fi

	if ((result)); then
		echo -e "\n${output::-3}\n"
	fi

	return $result
}

# Create the given Elasticsearch user.
function create_user {
	local username=$1
	local password=$2
	local role=$3



	local -a args=( '-s' '-D-' '-m15' '-w' '%{http_code}'
		"http://localhost:9200/_security/user/${username}"
		'-X' 'POST'
		'-H' 'Content-Type: application/json'
		'-d' "{\"password\":\"${password}\",\"roles\":[\"${role}\"]}"
		)

	if [[ -n "${ELASTIC_PASSWORD:-}" ]]; then
		args+=( '-u' "elastic:${ELASTIC_PASSWORD}" )
	fi

	local -i result=1
	local output

	output="$(curl "${args[@]}")"
	if [[ "${output: -3}" -eq 200 ]]; then
		result=0
	fi

	if ((result)); then
		echo -e "\n${output::-3}\n"
	fi

	return $result
}

# Ensure that the given Elasticsearch role is up-to-date, create it if required.
function ensure_role {
	local name=$1
	local body=$2
	local -a args=( '-s' '-D-' '-m15' '-w' '%{http_code}'
		"http://localhost:9200/_security/role/${name}"
		'-X' 'POST'
		'-H' 'Content-Type: application/json'
		'-d' "$body"
		)

	if [[ -n "${ELASTIC_PASSWORD:-}" ]]; then
		args+=( '-u' "elastic:${ELASTIC_PASSWORD}" )
	fi

	local -i result=1
	local output

	output="$(curl "${args[@]}")"
	if [[ "${output: -3}" -eq 200 ]]; then
		result=0
	fi

	if ((result)); then
		echo -e "\n${output::-3}\n"
	fi

	return $result
}

EOF
chmod +x lib.sh
cat > entrypoint.sh <<'EOF'

#!/usr/bin/env bash

set -eu
set -o pipefail

source "${BASH_SOURCE[0]%/*}"/lib.sh


# --------------------------------------------------------
# Users declarations

declare -A users_passwords
users_passwords=(
	[logstash_internal]="${LOGSTASH_INTERNAL_PASSWORD:-}"
	[kibana_system]="${KIBANA_SYSTEM_PASSWORD:-}"
	[metricbeat_internal]="${METRICBEAT_INTERNAL_PASSWORD:-}"
	[filebeat_internal]="${FILEBEAT_INTERNAL_PASSWORD:-}"
	[heartbeat_internal]="${HEARTBEAT_INTERNAL_PASSWORD:-}"
	[monitoring_internal]="${MONITORING_INTERNAL_PASSWORD:-}"
	[beats_system]="${BEATS_SYSTEM_PASSWORD=:-}"
)

declare -A users_roles
users_roles=(
	[logstash_internal]='logstash_writer'
	[metricbeat_internal]='metricbeat_writer'
	[filebeat_internal]='filebeat_writer'
	[heartbeat_internal]='heartbeat_writer'
	[monitoring_internal]='remote_monitoring_collector'
)

# --------------------------------------------------------
# Roles declarations

declare -A roles_files
roles_files=(
	[logstash_writer]='logstash_writer.json'
	[metricbeat_writer]='metricbeat_writer.json'
	[filebeat_writer]='filebeat_writer.json'
	[heartbeat_writer]='heartbeat_writer.json'
)

# --------------------------------------------------------


log 'Waiting for availability of Elasticsearch. This can take several minutes.'

declare -i exit_code=0
wait_for_elasticsearch || exit_code=$?

if ((exit_code)); then
	case $exit_code in
		6)
			suberr 'Could not resolve host. Is Elasticsearch running?'
			;;
		7)
			suberr 'Failed to connect to host. Is Elasticsearch healthy?'
			;;
		28)
			suberr 'Timeout connecting to host. Is Elasticsearch healthy?'
			;;
		*)
			suberr "Connection to Elasticsearch failed. Exit code: ${exit_code}"
			;;
	esac

	exit $exit_code
fi

sublog 'Elasticsearch is running'

log 'Waiting for initialization of built-in users'

wait_for_builtin_users || exit_code=$?

if ((exit_code)); then
	suberr 'Timed out waiting for condition'
	exit $exit_code
fi

sublog 'Built-in users were initialized'

for role in "${!roles_files[@]}"; do
	log "Role '$role'"

	declare body_file
	body_file="${BASH_SOURCE[0]%/*}/roles/${roles_files[$role]:-}"
	if [[ ! -f "${body_file:-}" ]]; then
		sublog "No role body found at '${body_file}', skipping"
		continue
	fi

	sublog 'Creating/updating'
	ensure_role "$role" "$(<"${body_file}")"
done

for user in "${!users_passwords[@]}"; do
	log "User '$user'"
	if [[ -z "${users_passwords[$user]:-}" ]]; then
		sublog 'No password defined, skipping'
		continue
	fi

	declare -i user_exists=0
	user_exists="$(check_user_exists "$user")"

	if ((user_exists)); then
		sublog 'User exists, setting password'
		set_user_password "$user" "${users_passwords[$user]}"
	else
		if [[ -z "${users_roles[$user]:-}" ]]; then
			suberr '  No role defined, skipping creation'
			continue
		fi

		sublog 'User does not exist, creating'
		create_user "$user" "${users_passwords[$user]}" "${users_roles[$user]}"
	fi
done
EOF
chmod +x entrypoint.sh
./entrypoint.sh
rm entrypoint.sh
rm lib.sh
rm -r roles
```



#### kibana 配置

修改 `./docker_data/elk/kibana.yml` 文件，使用下列信息进行覆盖

```yaml
## Default Kibana configuration from Kibana base image.
## https://github.com/elastic/kibana/blob/main/src/dev/build/tasks/os_packages/docker_generator/templates/kibana_yml.template.ts
#
server.name: kibana
server.host: 0.0.0.0
elasticsearch.hosts: [ http://snaplink-elasticsearch:9200 ]

monitoring.ui.container.elasticsearch.enabled: true
monitoring.ui.container.logstash.enabled: true

## X-Pack security credentials
#
elasticsearch.username: kibana_system
elasticsearch.password: ${KIBANA_SYSTEM_PASSWORD}

## Encryption keys (optional but highly recommended)
##
## Generate with either
##  $ docker container run --rm docker.elastic.co/kibana/kibana:8.6.2 bin/kibana-encryption-keys generate
##  $ openssl rand -hex 32
##
## https://www.elastic.co/guide/en/kibana/current/using-kibana-with-security.html
## https://www.elastic.co/guide/en/kibana/current/kibana-encryption-keys.html
#
#xpack.security.encryptionKey:
#xpack.encryptedSavedObjects.encryptionKey:
#xpack.reporting.encryptionKey:

## Fleet
## https://www.elastic.co/guide/en/kibana/current/fleet-settings-kb.html
#
xpack.fleet.agents.fleet_server.hosts: [ http://fleet-server:8220 ]

xpack.fleet.outputs:
  - id: fleet-default-output
    name: default
    type: elasticsearch
    hosts: [ http://snaplink-elasticsearch:9200 ]
    is_default: true
    is_default_monitoring: true

xpack.fleet.packages:
  - name: fleet_server
    version: latest
  - name: system
    version: latest
  - name: elastic_agent
    version: latest
  - name: apm
    version: latest

xpack.fleet.agentPolicies:
  - name: Fleet Server Policy
    id: fleet-server-policy
    description: Static agent policy for Fleet Server
    monitoring_enabled:
      - logs
      - metrics
    package_policies:
      - name: fleet_server-1
        package:
          name: fleet_server
      - name: system-1
        package:
          name: system
      - name: elastic_agent-1
        package:
          name: elastic_agent
  - name: Agent Policy APM Server
    id: agent-policy-apm-server
    description: Static agent policy for the APM Server integration
    monitoring_enabled:
      - logs
      - metrics
    package_policies:
      - name: system-1
        package:
          name: system
      - name: elastic_agent-1
        package:
          name: elastic_agent
      - name: apm-1
        package:
          name: apm
        # See the APM package manifest for a list of possible inputs.
        # https://github.com/elastic/apm-server/blob/v8.5.0/apmpackage/apm/manifest.yml#L41-L168
        inputs:
          - type: apm
            vars:
              - name: host
                value: 0.0.0.0:8200
              - name: url
                value: http://apm-server:8200
# 中文支持
i18n.locale: "zh-CN"
```

重新启动后访问：http://localhost:5601/login

账户密码：

```
username: elastic Stack
# 在docker compose 中的 ELASTIC_PASSWORD 环境变量设置 
password: StJffdEsZC
```

进入后按照下面的流程进行配置

![](https://cimg.anubis.cafe/2024/04/0b73cbc2767720d31014e054a791cadd.gif)

#### logstash 配置

修改 `./docker_data/elk/logstash.yml` 文件，使用下列信息进行覆盖

```yaml
## Default Logstash configuration from Logstash base image.
## https://github.com/elastic/logstash/blob/main/docker/data/logstash/config/logstash-full.yml
#
http.host: 0.0.0.0
node.name: logstash
xpack.management.enabled: true
# 此 id 影响 logstash 的 pipelin 管理
xpack.management.pipeline.id: ["main", "snaplink"]
# 此账户在 kibana 中创建
xpack.management.elasticsearch.username: "logstash_user"
# 此处密码需要从上个流程在获取
xpack.management.elasticsearch.password: "e3pXDNnbpbDQc2f"
# 此处与 docker-ompose 中的 hostname 相关
xpack.management.elasticsearch.hosts: ["snaplink-elasticsearch"]
```

待上面的 es 跟 kibana 均启动后再启动 logstash

再次进入 [kibana 控制台](http://localhost:5601/app/management/ingest/pipelines)

创建管道 snaplink ，配置内容如下

> 以下列配置为准，gif 中有配置错误

```
input {
  rabbitmq {
    host => "snaplink-rabbitmq"
    port => 5672  # RabbitMQ服务的端口，默认为5672
    user => "elk"
    password => "elk"
    vhost => "accesslog"
    queue => "accessLog"
    durable => true
    codec => "json" 
  }
}
filter {
    date {
        match => ["datetime", "YYYY-MM-dd HH:mm:ss"]
        target => "@timestamp"
    }
    useragent {
        source => "[header][User-Agent][0]"  # 使用正确的字段路径
        target => "ua"  # 将解析结果存储在ua字段中
    }
    geoip {
        source =>  "[ip]"  # 使用正确的字段路径
        target => "client.geo"
    }
    mutate {
        remove_field => ["header", "requestID", "datetime","event", "@version"]
    }
}
output {
    elasticsearch {
		hosts => "snaplink-elasticsearch:9200"
		user => "logstash_internal"
		password => "${LOGSTASH_INTERNAL_PASSWORD}"
        index => "logstash-accesslog-%{+YYYY.MM.dd.HH}"
    }
}
```

![](https://cimg.anubis.cafe/2024/04/415eacd5e0622794828ae8e877534b7d.gif)

进入 RabbitMQ 控制面板查看，存在下列链接，即为成功配置

![](https://cimg.anubis.cafe/2024/04/c36f30c02b0ac4daadb6bc47dbaf7347.webp)